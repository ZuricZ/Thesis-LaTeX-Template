\section{Well-posedness of the backward equations}
\label{apx:wellposedness}

The following assumption is needed to treat the (multi-dimensional) Markovian case,
while Assumption~\ref{ass:wellposednessBSPDE} is required for the (one-dimensional) non-Markovian case.

\begin{assumption}[Well-possedness of the FBSDE system~\eqref{eq:markovianSDE}-\eqref{eq:markovianBSDE}]\label{ass:wellposednessBSDE}
The drift $\mu: [0, T]\times\RR^d\rightarrow\RR^d$ and the diffusion coefficient $\Sigma:[0, T]\times\RR^d\rightarrow\RR^d\times\RR^d$ satisfy global Lipschitz conditions. Moreover,
\begin{enumerate}[i)]
    \item there exists $L_f>0$ such that the driver $f:[0,T]\times \RR^d \times \RR \times \RR^{d} \rightarrow \RR$ satisfies
    \begin{align*}
    &\left|f\left(t_2, x_2, y_2, z_2\right)-f\left(t_1, x_1, y_1, z_1\right)\right| \\
    & \hspace{2cm} \leq L_f\left(\sqrt{\left|t_2-t_1\right|}+\left|x_2-x_1\right|+\left|y_2-y_1\right|+\left|z_2-z_1\right|\right),
    \end{align*}
    for all $\left(t_1, x_1, y_1, z_1\right)$ and $\left(t_2, x_2, y_2, z_2\right) \in[0, T] \times \RR^d \times \RR \times \RR^{d}$. Furthermore,
    $$
    \sup_{0 \leq t \leq T}\|f(t, 0,0,0)\|<\infty .
    $$
    \item The function~$g$ has at most linear growth condition.
\end{enumerate}
\end{assumption}
\begin{assumption}\label{ass:wellposednessBSPDE}
Let $g:\RR\rightarrow\RR$ and $f:[0,T]\times\RR^4\rightarrow\RR$
be deterministic functions for which the following holds:
\begin{enumerate}[i)]
    \item $g$ admits at most linear growth;
    \item $f$ is $L_f$-Lipschitz in all space arguments and there exists $L_0>0$ such that
    $$
    |f(t,x,0,0,0)| \leq L_f(1+|x|) 
        \qquad\text{and}\qquad
        |f(t,x,y,z,\widetilde{z})-f(t,x,y,0,0)| \leq L_0.
        $$\end{enumerate}
\end{assumption}
\section{Error bounds for RWNN}\label{apx:errorRWNN}

% \begin{proposition}[Proposition 3 in~\cite{Gonon2020ApproximationSystems}]\label{prop:UATRWNN}
% Suppose $\psi^{*}: \RR^{q} \rightarrow \RR$ can be represented as
% $$
% \psi^{*}(z)=\int_{\RR^{q}} \E^{\I\theta^\top z} g(\theta) \D \theta,
% $$
% for some complex-valued function~$g$ on $\RR^{q}$ and all $z \in \RR^{q}$ with $\|z\| \leq Q$. Assume that
% $$
% \int_{\RR^{q}} \max \left(1,\|\theta \|^{2 q+6}\right)|g(\theta)|^{2} \D \theta <\infty .
% $$
% Let $R>0$, suppose the rows of the $K\times K$-valued random matrix~$\Am$ are iid Uniform on $\Bb_{R} \subset \RR^{q}$, that the entries of $\bm\in\RR^{K}$ are iid Uniform on $[-\max (Q R, 1), \max (Q R, 1)]$, 
% that~$\Am$ and~$\bm$ are independent and let $\relu(x)\coloneqq \max (x, 0)$ on~$\RR$. 
% Let the pair $(A,b)$ characterise a random basis (reservoir)~$\Phi$ and its corresponding network $\Psi\in\RWNN^{\relu}_K$ in the sense of Definition~\ref{def:RWNN}. 
% Then, there exists an $\RR^K$-valued random variable~$\Theta$ and $C^{*}>0$ 
% (given explicitly in~\cite[Equation~(33)]{Gonon2020ApproximationSystems}) such that
% $$
% \EE^\Phi\left[\left\|\Psi(Z;\Theta) - \psi^{*}(Z)\right\|^{2}\right] \leq \frac{C^{*}}{K},
% $$
% and for any $\delta \in(0,1)$, with probability $1-\delta$ the random neural network $\Psi(\cdot;\Theta)$ satisfies
% $$
% \left(\int_{\RR^{q}}\left\|\Psi(z;\Theta) - \psi^{*}(z)\right\|^{2} \mu_{Z}(\D z)\right)^{1 / 2} \leq \frac{\sqrt{C^{*}}}{\delta \sqrt{K}}.
% $$
% \end{proposition}

\begin{lemma}\label{lem:sol_as_RWNN}
For any $t_i\in\pi$, 
there exists~$g$ as in Proposition~\ref{prop:UATRWNN}
such that solutions $\mathfrak{f}\in\{u(t_i, \cdot), \psi(t_i, \cdot)\}$ to the BSPDE~\eqref{eq:BSPDEGeneral} can be represented as
$$
\mathfrak{f}(z)=\int_{\RR^q} \E^{\I\theta^\top z} g(\theta) \D \theta,
\qquad\text{ for all }z\in\RR^q.
$$
\end{lemma}
\begin{proof}

A sufficient condition for the above condition to be satisfied is that $\mathfrak{f} \in L^{1}\left(\mathbb{R}^{q}\right)$
has an integrable Fourier transform and belongs to the Sobolev space $\Ww^{2,2}\left(\mathbb{R}^{q}\right)$ (see e.g. \cite[Theorem~6.1]{Folland1995IntroductionEquations}). 
In our case, i.e., for $q=1$ and under assumption $\mathfrak{f}\in \Ww^{3,2}(\RR^1)$ as enforced by Assumption~\ref{ass:RWNNscheme}~i), we have by~\cite[Theorem~9.17]{Folland2013RealApplications} that $\|\widehat{(\Dr^{\boldsymbol\alpha} \mathfrak{f})}\|_{(1)} \leq C \|\mathfrak{f}\|_{(3)}$ for all multi-indices $|\boldsymbol\alpha|\leq 2$ and $\|\mathfrak f\|_{(s)}=[\int|\widehat{\mathfrak f}(\xi)|^2\left(1+|\xi|^2\right)^s \D \xi]^{1 / 2}$ for~$s\in\RR$ denotes the Sobolev norm. Thus, we have by \cite[Corollary~2.52]{Folland2013RealApplications} that $\widehat{ \mathfrak{f}} \in L^1(\RR^1)$.
\end{proof}


\section{Proof of Theorem~\ref{thm:convergence}}
\label{apx:technical_proofs_RWNN}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We prove the theorem in three steps. 
First, we derive an estimate for the $L^2$\nobreakdash-distance of~$\widehat{\Vv}_{t_i}$ to the discretised~$Y_{t_i}$. Next, we use this to prove the estimate for the $Y$\nobreakdash-component and finally for the $Z$\nobreakdash-components. 
In the first part, for convenience, we do not explicitly denote the conditionality of expectation on the realisation of random bases of the corresponding RWNNs, but remark that the expectation should be understood as such whenever this is the case. For convenience, we introduce the error notations:
\begin{equation}\label{eq:ErrorNotations}
\begin{array}{rll}
\Ef\left[A, B\right] & \coloneqq \EE\left[\left|A-B\right|^2\right], & 
    \Df_i\left[A, B\right] \coloneqq \EE_i\left[\left|A - B\right|\right], \\
    \If_i\left[A(t), B(t_i)\right] & \displaystyle \coloneqq \EE\left[\int_{t_i}^{t_{i+1}}\left|A(t) - B(t_i)\right|^2 \D t \right],
\end{array}
\end{equation}
where the error rates~$\Df$ and~$\If$ are implicitly related to the partition~$\pi$ through the index $i\in\{0,\dots,N-1\}$.
We further denote
$f_{t} \coloneqq  f\left(t, X_t, Y_t, Z^1_t, Z^2_t\right)$
and note that the constant $C>0$ might change from line to line.

\paragraph{\textbf{Part I}} We start by showing for each $i\in\{0, \dots, N-1\}$,
\begin{small}
\begin{equation}\label{eq:convergence_part1_result}
\ErrYiVhat
\leq (1+C|\pi|) \ErrYiUfip
 +C|\pi| \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right] 
 + C \sum_{k=1}^{2}\ErrIntZkibar + C |\pi|\omega(|\pi|),
\end{equation}
\end{small}%
where $\omega$ is the modulus function from Assumption~\ref{ass:RWNNscheme}. 
By writing the SPDE as the corresponding BSPDE as in~\eqref{eq:BSDEGeneral} and using~\eqref{eq:auxilaryProcesses}, we obtain
\begin{small}
\begin{equation}
Y_{t_i}-\widehat{\Vv}_{t_i} = 
\EE_i\left[Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right]+\EE_i\left[\int_{t_i}^{t_{i+1}} f\left(t, \E^{X_t}, Y_t, Z^1_t, Z^2_t\right)-f\left(t_i, \E^{X^\pi_{t_i}}, \widehat{\Vv}_{t_i}, \ZowO_{t_{i}}, \ZowT_{t_{i}}\right) \D t\right]\,.
\end{equation}
\end{small}%
Then, Young's inequality~\eqref{eq:Young} with $\chi = \gamma\Deli$ gives
\begin{small}
\begin{equation}
\begin{aligned}
&\ErrYiVhat \\
& \leq \EE\left\{\left(1+\gamma \Deli \right)
\ErriYiUfip^{2}
 + \left(1+\frac{1}{\gamma \Deli }\right)\EE_i\left[\int_{t_i}^{t_{i+1}}\left\{
f_{t}-f\left(t_i, \E^{X^\pi_{t_i}}, \widehat{\Vv}_{t_i}, \ZowO_{t_{i}}, \ZowT_{t_{i}}\right)\right\} \D t\right]^2\right\}\,.
\end{aligned}
\end{equation}
\end{small}%
Then Cauchy-Schwarz, Assumption~\ref{ass:RWNNscheme} and~\eqref{eq:fwd_process_estimation} imply
\begin{align}\label{eq:convergence_part1_0}
\begin{split}
\ErrYiVhat &\leq \left(1+\gamma \Deli \right) \EE\left[\ErriYiUfip^2\right] \\ 
& + 5\left(1+\frac{1}{\gamma \Deli }\right) L_f^2 \Deli \Bigg\{C |\pi| \omega(|\pi|)
+ \ErrIntYtVihat + \sum_{k=1}^{2}\ErrIntZkihat\Bigg\}\,.
\end{split}
\end{align}
The standard inequality $(a+b)^2\leq 2(|a|^2+|b|^2)$ and the $L^2$-regularity of~$Y$ in~\eqref{eq:L2regularity} yield
\begin{align*}
\ErrIntYtVihat 
 & = \EE\left[\int_{t_i}^{t_{i+1}}|Y_t - \widehat \Vv_{t_i}|^2\D t\right] = \EE\left[\int_{t_i}^{t_{i+1}}|Y_t-Y_{t_i}+Y_{t_i}-\widehat\Vv_{t_i}|^2 \D t\right]\\
  & \leq 2 \EE\left[\int_{t_i}^{t_{i+1}}
\left\{|Y_t-Y_{t_i}|^2 + \left|Y_{t_i}-\widehat\Vv_{t_i}\right|^2\right\} \D t\right] \\
 & \leq 2|\pi|^2 + 2\Deli\EE\left[|Y_{t_i}-\widehat\Vv_{t_i}|^2\right]
 = 2|\pi|^2 + 2\Deli\ErrYiVhat\,,
\end{align*}
so that after rearranging the constant term $\left(1+\frac{1}{\gamma\Deli}\right)L_f^2\Deli=(1+\gamma\Deli)\frac{L_f^2}\gamma$,
we obtain
\begin{equation}
\begin{aligned}
\ErrYiVhat &\leq \left(1+\gamma \Deli \right) \EE\left[\ErriYiUfip^{2}\right] \\
 & \qquad + 5\left(1+\gamma \Deli \right) \frac{L_f^2}{\gamma}\left\{
C |\pi| \omega(|\pi|) + \Deli  \ErrYiVhat
+ \sum_{k=1}^{2}\ErrIntZkihat\right\}\,.
\end{aligned}
\end{equation}
Since $\overline{Z}^k$ are defined as $L^2$-projections of $Z$ (see \eqref{eq:Z_error}), the last term reads
\begin{align}\label{eq:convergence_part1}
\begin{split}
& \ErrYiVhat \leq\left(1+\gamma \Deli \right) \EE\left[\ErriYiUfip^2\right] \\
 & \qquad + 5\left(1+\gamma \Deli \right) \frac{L_f^2}{\gamma}\Bigg\{C |\pi| \omega(|\pi|) + 2 \Deli  \ErrYiVhat 
+ \sum_{k=1}^2\left(\ErrIntZkibar + \Deli \ErrZkibarhat \right)\Bigg\}\,.
\end{split}
\end{align}
The rightmost term can be further expanded:
integrating the BSDE~\eqref{eq:BSDEGeneral} over $[t_i, t_{i+1}]$, multiplying it by $\Delta^{W^k}_{i}$ for $k\in\{1,2\}$ separately and using the definitions in~\eqref{eq:auxilaryProcesses} give
\begin{align}
\Deli \left[\overline{Z}^k_{t_i}-\Zowk_{t_{i}}\right] &= \EE_i\left[\Delta^{W^k}_{i}\left\{Y_{t_{i+1}}-\widehat{\Uf}_{i+1}-\EE_i\left[Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right]\right\}\right] 
+ \EE_i\left[\Delta^{W^k}_{i} \int_{t_i}^{t_{i+1}} f_{t}\D t\right]\,.
\end{align}
Next, taking the expectation of the square and using the H{\"o}lder inequality yield
\begin{small}
\begin{align*}
    & \frac{\Deli^2}{2}
    \EE_i\left[\left|\overline{Z}^k_{t_i} - \Zowk_{t_{i}}\right|^2\right] \\
    &\leq \left|\EE_i\left[\Delta^{W^k}_{i}\left\{Y_{t_{i+1}}-\widehat{\Uf}_{i+1}-\EE_i\left[Y_{t_{i+1}} - \widehat{\Uf}_{i+1}\right]\right\}\right]\right|^2 + \left|\EE_i\left[\Delta^{W^k}_{i} \int_{t_i}^{t_{i+1}} f_{t}\D t\right]\right|^2 \\
    &\leq \EE_i\left[\left|\Delta^{W^k}_{i}\right|^2\right] \EE_i\left[\left| Y_{t_{i+1}}-\widehat{\Uf}_{i+1} - \EE_i\left[Y_{t_{i+1}} - \widehat{\Uf}_{i+1}\right]\right|^2\right] + \EE_i\left[ \left|\Delta^{W^k}_{i}\right|^2\right]\EE_i\left[ \left|\int_{t_i}^{t_{i+1}} f_{t}\D t\right|^2\right] \\
    &= \Deli \Bigg\{\EE_i\left[\left| Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right|^2\right] -2\EE_i\left[\left(Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right)\EE_i\left[Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right]\right] + \left|\EE_i\left[ Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right]\right|^2 \\
    & \qquad + \EE_i\left[ \left|\int_{t_i}^{t_{i+1}} f_{t}\D t\right|^2\right]\Bigg\} \\
    &\leq \Deli \left\{\EE_i\left[\left| Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right|^2\right] - \left|\EE_i\left[ Y_{t_{i+1}}-\widehat{\Uf}_{i+1}\right]\right|^2 + \EE_i\left[\int_{t_i}^{t_{i+1}}\D t  \int_{t_i}^{t_{i+1}} \left| f_{t}\right|^2\D t\right]\right\}\,.
\end{align*}
\end{small}%
Finally, by the law of iterated conditional expectations
\begin{equation}\label{eq:convergence_part1_2}
\frac{\Deli}{2}
\EE\left[\left|\overline{Z}^k_{t_i} - \Zowk_{t_{i}}\right|^2\right]
\leq \ErrYiUfip
- \EE\left[\ErriYiUfip^{2}\right]
 + \Deli  \EE\left[\int_{t_i}^{t_{i+1}}
f_{t}^2 \D t\right]\,,
\end{equation}
which can then be used in~\eqref{eq:convergence_part1} to obtain
\begin{small}
\begin{align}
\begin{split}
& \ErrYiVhat \\
& \leq\left(1+\gamma \Deli \right) \EE\left[\ErriYiUfip^2\right] 
 + 5\left(1+\gamma \Deli \right) \frac{L_f^2}{\gamma}\Bigg\{C |\pi| \omega(|\pi|) + 2\Deli  \ErrYiVhat \\
&\qquad +\sum_{k=1}^2\ErrIntZkibar + 4\left(\ErrYiUfip - \EE\left[\ErriYiUfip^{2}\right]\right)
 + 4 \Deli  \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right]\Bigg\} \\
& \leq \left(1+20 L_f^2 \Deli \right) \ErrYiUfip \\
& \qquad + C \left\{|\pi| \omega(|\pi|) + \Deli \ErrYiVhat + \sum_{k=1}^{2}\ErrIntZkibar  + \Deli  \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right]\right\}\,,
\end{split}
\end{align}
\end{small}%
with $\gamma = 20 L_f^2$ in the second inequality, concluding Part~I by letting~$|\pi|$ sufficiently small.

\paragraph{\textbf{Part II}} 
We now prove an estimate for the $Y$-component and show that
\begin{align}\label{eq:convergence_part2_result}
\max_{i\in\{0,\dots,N-1\}} 
\ErrYiUfi \leq C\Bigg\{\omega(|\pi|) + \EE\left[\left|g(X_T)-g(X^\pi_T)\right|^2\right]+\sum_{k=1}^2\eps^{Z^k}(\pi)+\frac{C^{*}}{K}N + M|\pi|^2\Bigg\}\,.
\end{align}
With Young's inequality of the form $(a+b)^2\geq (1-|\pi|)a^2 - \frac1{|\pi|} b^2$,
we have
\begin{equation}
\ErrYiVhat = \EE\left[\left|Y_{t_i} - \widehat{\Uf}_i + \widehat{\Uf}_i - \widehat{\Vv}_{t_i}\right|^2\right] 
\geq (1-|\pi|)\ErrYiUfi - \frac1{|\pi|} \ErrVhatiUfi\,.
\end{equation}
Since $\frac1{|\pi|}\leq \frac{N}{T}=CN$,
taking small enough~$|\pi|$, 
\begin{equation}\label{eq:convergence_part1_3}
\ErrYiUfi \leq \frac{\ErrYiVhat + CN \ErrVhatiUfi}{(1-|\pi|)}
    \leq C \left\{
\ErrYiVhat + CN \ErrVhatiUfi\right\}
\end{equation}
and combining~\eqref{eq:convergence_part1_result} from Part~I with~\eqref{eq:convergence_part1_3},
\begin{align*}
 \ErrYiUfi & \leq (1+C|\pi|) \ErrYiUfip \\
 & + C\left\{|\pi| \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right] + \sum_{k=1}^{2}\ErrIntZkibar + |\pi|\omega(|\pi|) + N\ErrVhatiUfi
  \right\}\,.
\end{align*}
After noting that $Y_{t_N}= g(X_T)$ and $\widehat{\Uf}_N= g(X^\pi_T)$, recalling the definition of $\eps^{Z^k}(\pi)$ from~\eqref{eq:Z_error} and the $L^2$-integrability of $f$ in~\eqref{eq:L2int_f}, 
straightforward induction implies
\begin{align*}
&\max_{i\in\{0, \dots, N-1\}}\ErrYiUfi \\
&\qquad\leq C\Bigg\{\omega(|\pi|) + |\pi| + \EE\left[\left|g(X_t)-g(X^\pi_T)\right|^2\right] + \sum_{k=1}^2\eps^{Z_k}(\pi)
 + N\sum_{i=0}^{N-1}\ErrVhatiUfi\Bigg\}\,.
\end{align*}
Finally, this in conjunction with Lemma~\ref{lem:step_RWWN_bound}, safely ignoring the $Z$-component on the left-hand side, since it is positive, gives the desired result~\eqref{eq:convergence_part2_result}.

\paragraph{\textbf{Part III}} 
Finally, we prove the following bound on the~$Z$ components:
\begin{align}\label{eq:convergence_part3_result}
\begin{split}
 &\EE\left[\sum_{i=0}^{N-1} \int_{t_i}^{t_{i+1}}\sum_{k=1}^2\left|Z_t^k-\widehat{\mathcal{Z}}^k_i\left(X^\pi_{t_i}\right)\right|^2 \D t\right] \\
 &\qquad\leq C\Bigg\{\omega(|\pi|) + \EE\left[\left|g(X_T)-g(X^\pi_T)\right|^2\right]+\sum_{k=1}^2\eps^{Z^k}(\pi)+\frac{C^{*}}{K}N + M|\pi|^2\Bigg\}\,.
 \end{split}
\end{align}
Since~$\overline{Z}^k$ are $L^2$-projections of~$Z$,
\begin{align*}
\ErrIntZkihat 
&= \EE\left[\int_{t_i}^{t_{i+1}}\left|Z^k_t - \overline{Z}^{k}_{t_{i}} + \overline{Z}^{k}_{t_{i}} - \Zowk_{t_{i}}\right|^2\D t\right] \\
 &= \EE\left[ \int_{t_i}^{t_{i+1}}\left\{
 \left|Z^k_t - \overline{Z}^{k}_{t_{i}}\right|^2 + \left|\overline{Z}^{k}_{t_{i}} - \Zowk_{t_{i}}\right|^2 +
 2
 \left|\overline{Z}^{k}_{t_{i}} - \Zowk_{t_{i}}\right|
 \left|Z^k_t - \overline{Z}^{k}_{t_{i}}\right|
 \right\}\D t \right]\\
 &= \ErrIntZkibar + \Deli \ErrZkibarhat \\
 &\qquad + 2\EE\left[\left|\overline{Z}^{k}_{t_{i}} - \Zowk_{t_{i}}\right| \int_{t_i}^{t_{i+1}}\left|Z^k_t - \frac{1}{\Deli} \EE_{i}\left[\int_{t_{i}}^{t_{i+1}} Z^k_{s} \D s\right]\right| \D t \right]\,,
\end{align*}
and the mixed term cancels by the tower property. 
Using~\eqref{eq:convergence_part1_2} below yields
\begin{small}
\begin{align*}
\ErrIntZkihat
& =\ErrIntZkibar + \Deli \ErrZkibarhat \\
&\leq \ErrIntZkibar +  2 \left\{\ErrYiUfip
 - \EE\left[\ErriYiUfip\right]\right\}
 + 2 |\pi| \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right]\,,
\end{align*}
\end{small}%
for $k\in\{1,2\}$. 
Summing over $i\in\{0,\dots,N-1\}$ together with~\eqref{eq:L2int_f} implies
\begin{equation}\label{eq:convergence_part3_0}
\begin{aligned}
\ErrIntZkihat &\leq \eps^{Z^k}(\pi) + 2\EE\left[\left|g(X_T)-g(X^\pi_T)\right|^2\right] \\
& \qquad + 2\sum_{i=0}^{N-1}\left\{\ErrYiUfi - \EE\left[\ErriYiUfip^{2}\right]\right\} + C|\pi|\,.
\end{aligned}
\end{equation}
The summation index was changed in the first term in the curly braces to apply the terminal conditions $Y_{t_N}\coloneqq g(X_T)$ and $\widehat{\Uf}_N(X^\pi_{t_N})\coloneqq g(X^\pi_T)$.
Combining~\eqref{eq:convergence_part1_0} and~\eqref{eq:convergence_part1_3},
\begin{equation}
\begin{aligned}
& 2\left\{\ErrYiUfi - \EE\left[\ErriYiUfip\right]\right\} \\
& \qquad\leq \frac{3 \ErrVhatiUfi}{|\pi|(1-|\pi|)} + \frac{2}{1-|\pi|}\Bigg\{\left(1+\gamma |\pi|\right) \EE\left[\ErriYiUfip^{2}\right] \\ 
& \qquad + \frac{5\left(1+\gamma |\pi|\right) L_f^2}{\gamma}\left[C |\pi|\omega(|\pi|) +2|\pi| \ErrYiVhat + \sum_{k=1}^{2}\ErrIntZkihat\right]\Bigg\}\,.
\end{aligned}
\end{equation}
Plugging this back into~\eqref{eq:convergence_part3_0} gives
\begin{equation}
\begin{aligned}
&\ErrIntZkihat \leq \eps^{Z^k}(\pi) + 2\EE\left[\left|g(X_T)-g(X^\pi_T)\right|^2\right] \\ 
& \qquad + \sum_{i=0}^{N-1} \frac{3}{|\pi|(1-|\pi|)} \ErrVhatiUfi +
\sum_{i=0}^{N-1}\Bigg\{2\frac{1+\gamma |\pi|}{1-|\pi|} \EE\left[\ErriYiUfip\right] \\ 
& \qquad + \frac{\left(1+\gamma |\pi|\right)}{1-|\pi|} \frac{10 L_f^2}{\gamma}\left(C \omega(|\pi|)|\pi| +2|\pi| \ErrYiVhat + \sum_{k=1}^{2}\ErrIntZkihat\right)\Bigg\} + C|\pi|\,.
\end{aligned}
\end{equation}
Furthermore, choose $\gamma=50L_f^2$ so that $\frac{\left(1+\gamma |\pi|\right)}{1-|\pi|} \frac{10 L_f^2}{\gamma}\leq\frac14$ for small $|\pi|$, which in conjunction with $L^2$-integrability $f$ in~\eqref{eq:L2int_f}, Lemma~\ref{lem:step_RWWN_bound}, Part~I~\eqref{eq:convergence_part1_result}, Part~II~\eqref{eq:convergence_part2_result} gives
\begin{small}
\begin{equation}
\begin{aligned}
\frac{1}{2} \sum_{k=1}^2 \ErrIntZkihat
& \leq \sum_{k=1}^2\eps^{Z^k}(\pi) + C \Bigg\{\max _{i\in\{0, \dots, N\}} \ErrYiUfi + \omega(|\pi|) + \EE\left[\left|g\left(X_T\right)-g\left(X^\pi_T\right)\right|^2\right] \\
& \qquad + |\pi| \sum_{i=0}^{N-1} \ErrYiVhat
+ N \sum_{i=0}^{N-1} \ErrVhatiUfi + |\pi| \Bigg\}
\\
&\leq \sum_{k=1}^2\eps^{Z^k}(\pi) + C\Bigg\{\max _{i\in\{0, \dots, N\}} \ErrYiUfi + \omega(|\pi|) + |\pi| \\
& \qquad + |\pi| \sum_{i=0}^{N-1}\bigg\{C|\pi|\omega(|\pi|) + C \sum_{k=1}^2\ErrIntZkibar \\
& \qquad + (1+C|\pi|) \ErrYiUfip + |\pi| \EE\left[\int_{t_i}^{t_{i+1}}f_{t}^2 \D t\right]\bigg\}
 + N \sum_{i=0}^{N-1} \ErrVhatiUfi \Bigg\} \\
&\leq C\left\{\sum_{k=1}^2\eps^{Z^k}(\pi) + \omega(|\pi|)+|\pi|+\EE\left[\left|g\left(X_T\right)-g\left(X^\pi_T\right)\right|^2\right] + \frac{C^{*}}{K}N + M|\pi|^2\right\}\,.\label{eq:convergence_part3_1}
\end{aligned}
\end{equation}
\end{small}%
Ultimately, since~$\overline{Z}$ is an $L^2$-projection, we have the relation, for $k\in\{1,2\}$,
\begin{equation}
\EE\left[ \int_{t_i}^{t_{i+1}}\left|Z_t^k-\widehat{\mathcal{Z}}^k_i\left(X^\pi_{t_i}\right)\right|^2 \D t\right] \leq 2\ErrIntZkihat + 2\Deli  \EE\left[ \int_{t_i}^{t_{i+1}}\left|\Zowk_{t_{i}}-\widehat{\mathcal{Z}}^k_i\left(X^\pi_{t_i}\right)\right|^2 \D t\right]\,.
\end{equation}
Then Lemma~\ref{lem:step_RWWN_bound} applied over~$\Qq$ and summing over $i\in\{0,\dots,N-1\}$ yield Part~III.
